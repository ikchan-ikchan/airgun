<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>BB弾軌跡追跡デモ</title>
    <style>
      body { font-family: sans-serif; text-align: center; }
      video, canvas { display: block; margin: 10px auto; }
      #controls { margin: 10px; }
      #maxResolutionInfo { margin-top: 5px; font-size: 0.9em; color: #555; }
    </style>
  </head>
  <body>
    <h2>BB弾軌跡追跡デモ</h2>
    <div id="controls">
      <label for="cameraSelect">カメラ選択:</label>
      <select id="cameraSelect"></select>
      &nbsp;&nbsp;
      <label for="frameRateInput">フレームレート (fps):</label>
      <input type="number" id="frameRateInput" min="1" value="30" style="width:60px;">
      &nbsp;&nbsp;
      <label for="resPercentInput">解像度 (%):</label>
      <input type="number" id="resPercentInput" min="1" max="100" value="100" style="width:60px;">
      &nbsp;&nbsp;
      <button id="startButton">開始</button>
      <div id="maxResolutionInfo"></div>
    </div>
    
    <!-- カメラ映像（内部利用：Canvas に描画） -->
    <video id="video" autoplay muted playsinline style="display:none;"></video>
    <!-- 描画用キャンバス -->
    <canvas id="outputCanvas"></canvas>
    
    <script>
      const video = document.getElementById('video');
      const outputCanvas = document.getElementById('outputCanvas');
      const canvasCtx = outputCanvas.getContext('2d');
      const cameraSelect = document.getElementById('cameraSelect');
      const frameRateInput = document.getElementById('frameRateInput');
      const resPercentInput = document.getElementById('resPercentInput');
      const startButton = document.getElementById('startButton');
      const maxResolutionInfo = document.getElementById('maxResolutionInfo');
      
      let lastFrameData = null;
      // 軌跡の点を保存する配列（{x, y}）
      let trajectory = [];
      
      // 動体検出の際の輝度差の閾値（必要に応じて調整）
      const MOTION_THRESHOLD = 40; 
      // 検出対象の面積が一定以上の場合のみ弾とみなす（ノイズ除去のため）
      const MIN_BLOB_SIZE = 3; 
      
      // 利用可能なカメラを列挙する
      async function enumerateCameras() {
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(device => device.kind === 'videoinput');
          cameraSelect.innerHTML = '';
          videoDevices.forEach((device, index) => {
            const option = document.createElement('option');
            option.value = device.deviceId;
            option.text = device.label || `カメラ ${index + 1}`;
            cameraSelect.appendChild(option);
          });
        } catch (error) {
          console.error('カメラの列挙に失敗:', error);
        }
      }
      
      // 選択したカメラで、指定解像度・フレームレートで映像を取得する
      async function startCamera() {
        const selectedDeviceId = cameraSelect.value;
        // 制約なしで一旦ストリーム取得してcapabilities調査
        const tempConstraints = { video: { deviceId: { exact: selectedDeviceId } } };
        let tempStream;
        try {
          tempStream = await navigator.mediaDevices.getUserMedia(tempConstraints);
        } catch (error) {
          console.error('初回ストリーム取得に失敗:', error);
          return;
        }
        
        const videoTrack = tempStream.getVideoTracks()[0];
        const capabilities = videoTrack.getCapabilities();
        let maxWidth = (capabilities.width && capabilities.width.max) || 640;
        let maxHeight = (capabilities.height && capabilities.height.max) || 480;
        maxResolutionInfo.innerText = `このカメラの最大解像度: ${maxWidth} x ${maxHeight}`;
        tempStream.getTracks().forEach(track => track.stop());
        
        const resPercent = parseInt(resPercentInput.value) || 100;
        const desiredWidth = Math.floor(maxWidth * (resPercent / 100));
        const desiredHeight = Math.floor(maxHeight * (resPercent / 100));
        const frameRate = parseInt(frameRateInput.value) || 30;
        
        const constraints = {
          video: {
            deviceId: { exact: selectedDeviceId },
            width: { exact: desiredWidth },
            height: { exact: desiredHeight },
            frameRate: { ideal: frameRate }
          }
        };
        try {
          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
          return new Promise(resolve => {
            video.onloadedmetadata = () => {
              outputCanvas.width = video.videoWidth;
              outputCanvas.height = video.videoHeight;
              video.play();
              resolve();
            };
          });
        } catch (error) {
          console.error('カメラ映像の取得に失敗:', error);
        }
      }
      
      // 毎フレームごとの処理：フレーム差分で動き（弾）を検出し、軌跡描画
      function processFrame() {
        // 現在の映像をキャンバスに描画
        canvasCtx.drawImage(video, 0, 0, outputCanvas.width, outputCanvas.height);
        const frame = canvasCtx.getImageData(0, 0, outputCanvas.width, outputCanvas.height);
        const currentData = frame.data;
        
        let motionX = 0, motionY = 0, motionCount = 0;
        
        // 前フレームがあれば差分を計算
        if (lastFrameData) {
          for (let i = 0; i < currentData.length; i += 4) {
            // RGBの平均値で輝度とみなす
            const r = currentData[i];
            const g = currentData[i+1];
            const b = currentData[i+2];
            const currentGray = (r + g + b) / 3;
            
            const rLast = lastFrameData[i];
            const gLast = lastFrameData[i+1];
            const bLast = lastFrameData[i+2];
            const lastGray = (rLast + gLast + bLast) / 3;
            
            if (Math.abs(currentGray - lastGray) > MOTION_THRESHOLD) {
              // ピクセル番号から x,y 座標を計算
              const pixelIndex = i / 4;
              const x = pixelIndex % outputCanvas.width;
              const y = Math.floor(pixelIndex / outputCanvas.width);
              motionX += x;
              motionY += y;
              motionCount++;
            }
          }
        }
        
        // 過去のフレームを更新
        lastFrameData = new Uint8ClampedArray(currentData);
        
        // 動きがあればその中心座標を計算し軌跡として記録
        if (motionCount > MIN_BLOB_SIZE) {
          const centerX = motionX / motionCount;
          const centerY = motionY / motionCount;
          trajectory.push({ x: centerX, y: centerY });
        }
        
        // キャンバス上に軌跡を描画（直近の点同士をラインで結ぶ）
        if (trajectory.length > 1) {
          canvasCtx.beginPath();
          canvasCtx.lineWidth = 2;
          canvasCtx.strokeStyle = 'red';
          canvasCtx.moveTo(trajectory[0].x, trajectory[0].y);
          for (let i = 1; i < trajectory.length; i++) {
            canvasCtx.lineTo(trajectory[i].x, trajectory[i].y);
          }
          canvasCtx.stroke();
        }
        
        // 次のフレーム処理
        requestAnimationFrame(processFrame);
      }
      
      // スタートボタン押下時の処理
      startButton.addEventListener('click', async () => {
        // 軌跡や前フレームの初期化
        trajectory = [];
        lastFrameData = null;
        await startCamera();
        processFrame();
      });
      
      enumerateCameras();
    </script>
  </body>
</html>
